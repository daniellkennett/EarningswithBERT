{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e248df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in /home/daniel/anaconda3/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow-text) (2.4.1)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.19.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.32.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.36.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.15.7)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (54.1.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/daniel/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/daniel/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/daniel/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/daniel/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.7.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/daniel/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/daniel/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.4.1)\n",
      "\u001b[33mWARNING: Error parsing requirements for pymc3: [Errno 2] No such file or directory: '/home/daniel/anaconda3/lib/python3.7/site-packages/pymc3-3.8.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: bert-for-tf2 in /home/daniel/anaconda3/lib/python3.7/site-packages (0.14.9)\n",
      "Requirement already satisfied: py-params>=0.9.6 in /home/daniel/anaconda3/lib/python3.7/site-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: numpy in /home/daniel/anaconda3/lib/python3.7/site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.2)\n",
      "Requirement already satisfied: tqdm in /home/daniel/anaconda3/lib/python3.7/site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.59.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for pymc3: [Errno 2] No such file or directory: '/home/daniel/anaconda3/lib/python3.7/site-packages/pymc3-3.8.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: bert-tensorflow in /home/daniel/anaconda3/lib/python3.7/site-packages (1.0.4)\n",
      "Requirement already satisfied: six in /home/daniel/anaconda3/lib/python3.7/site-packages (from bert-tensorflow) (1.15.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for pymc3: [Errno 2] No such file or directory: '/home/daniel/anaconda3/lib/python3.7/site-packages/pymc3-3.8.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: tokenizers in /home/daniel/anaconda3/lib/python3.7/site-packages (0.10.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for pymc3: [Errno 2] No such file or directory: '/home/daniel/anaconda3/lib/python3.7/site-packages/pymc3-3.8.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text\n",
    "!pip install bert-for-tf2\n",
    "!pip install bert-tensorflow\n",
    "!pip install tokenizers\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a620a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference article for using code\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self, question, context, start_char_idx=None, answer_text=None, all_answers=None):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.all_answers = all_answers\n",
    "        self.skip = False\n",
    "        self.start_token_idx = -1\n",
    "        self.end_token_idx = -1\n",
    "\n",
    "    def preprocess(self):\n",
    "        # clean context and question\n",
    "        context = \" \".join(str(self.context).split())\n",
    "        question = \" \".join(str(self.question).split())\n",
    "        # tokenize context and question\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "        # if this is validation or training sample, preprocess answer\n",
    "        if self.answer_text is not None:\n",
    "            answer = \" \".join(str(self.answer_text).split())\n",
    "            # check if end character index is in the context\n",
    "            end_char_idx = self.start_char_idx + len(answer)\n",
    "            if end_char_idx >= len(context):\n",
    "                self.skip = True\n",
    "                return\n",
    "            # mark all the character indexes in context that are also in answer     \n",
    "            is_char_in_ans = [0] * len(context)\n",
    "            for idx in range(self.start_char_idx, end_char_idx):\n",
    "                is_char_in_ans[idx] = 1\n",
    "            ans_token_idx = []\n",
    "            # find all the tokens that are in the answers\n",
    "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "                if sum(is_char_in_ans[start:end]) > 0:\n",
    "                    ans_token_idx.append(idx)\n",
    "            if len(ans_token_idx) == 0:\n",
    "                self.skip = True\n",
    "                return\n",
    "            # get start and end token indexes\n",
    "            self.start_token_idx = ans_token_idx[0]\n",
    "            self.end_token_idx = ans_token_idx[-1]\n",
    "        # create inputs as usual\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        # add padding if necessary\n",
    "        if padding_length > 0:\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "        self.input_word_ids = input_ids\n",
    "        self.input_type_ids = token_type_ids\n",
    "        self.input_mask = attention_mask\n",
    "        self.context_token_to_char = tokenized_context.offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be95f733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                if \"answers\" in qa:\n",
    "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                    all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
    "                    start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                    squad_eg = Sample(question, context, start_char_idx, answer_text, all_answers)\n",
    "                else:\n",
    "                    squad_eg = Sample(question, context)\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_word_ids\": [],\n",
    "        \"input_type_ids\": [],\n",
    "        \"input_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "    x = [dataset_dict[\"input_word_ids\"],\n",
    "         dataset_dict[\"input_mask\"],\n",
    "         dataset_dict[\"input_type_ids\"]]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b7c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def normalize_text(self, text):\n",
    "        # convert to lower case\n",
    "        text = text.lower()\n",
    "        # remove redundant whitespaces\n",
    "        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
    "        # remove articles\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        text = re.sub(regex, \" \", text)\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # get the offsets of the first and last tokens of predicted answers\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "        # for every pair of offsets\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            # take the required Sample object with the ground-truth answers in it\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            # use offsets to get back the span of text corresponding to\n",
    "            # our predicted first and last tokens\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "            normalized_pred_ans = self.normalize_text(pred_ans)\n",
    "            # clean the real answers\n",
    "            normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n",
    "            # check if the predicted answer is in an array of the ground-truth answers\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81705159",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = keras.utils.get_file(\"train.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\")\n",
    "eval_path = keras.utils.get_file(\"eval.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
    "with open(train_path) as f: raw_train_data = json.load(f)\n",
    "with open(eval_path) as f: raw_eval_data = json.load(f)\n",
    "max_seq_length = 324\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
    "input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n",
    "\n",
    "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(sequence_output)\n",
    "start_logits = layers.Flatten()(start_logits)\n",
    "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(sequence_output)\n",
    "end_logits = layers.Flatten()(end_logits)\n",
    "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
    "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
    "model = keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=[start_probs, end_probs])\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam(lr=.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer=optimizer, loss=[loss, loss])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=1, batch_size=64, callbacks=[ValidationCallback(x_eval, y_eval)])\n",
    "model.save_weights('drive/MyDrive/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85898c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1Opq_CUoaf3qYv941wi3Mmme8skqVSfTk",
      "authorship_tag": "ABX9TyMFFCToVpskZ1UXfmLae9SR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniellkennett/Earnings_with_BERT/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRABXPpUWAZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f616c90a-1c3f-4be8-9ad4-384689510254"
      },
      "source": [
        "!pip install tensorflow-text\n",
        "!pip install bert-for-tf2\n",
        "!pip install bert-tensorflow\n",
        "!pip install tokenizers\n",
        "!pip install tensorflow-gpu as tf"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.10.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.10.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: as in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: tf in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.10.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoUdzmVWuCG4",
        "outputId": "d5448b0c-c58a-4ba0-8567-76755a3551f1"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHlBY33FuDTv",
        "outputId": "4d259ad7-5176-4b15-bef9-ac4000e82a0c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "1.6098916609989828\n",
            "GPU (s):\n",
            "0.03882466100185411\n",
            "GPU speedup over CPU: 41x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "opjpwN4OSV0e",
        "outputId": "a6e0a460-9966-4d69-b406-723f3ae9f3f7"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "!pip install tf-nightly "
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.7/dist-packages (2.6.0.dev20210423)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: tf-estimator-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.5.0.dev2021032601)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Collecting gast==0.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: tb-nightly~=2.6.0.a in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.6.0a20210423)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Collecting h5py~=3.1.0\n",
            "  Using cached https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: keras-nightly~=2.6.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.6.0.dev2021042300)\n",
            "Collecting grpcio<2.0,>=1.37.0\n",
            "  Using cached https://files.pythonhosted.org/packages/2c/8c/c4767d8f4e88a46983896ce3db52e972cbb9a9abc87a1625cbbc46c434ca/grpcio-1.37.0-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (0.6.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (56.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (3.10.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (3.4.1)\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.37.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.37.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, h5py, grpcio\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "Successfully installed gast-0.4.0 grpcio-1.37.0 h5py-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "grpc",
                  "h5py"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq9iMoKGcq05"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrQjfSaiZzap"
      },
      "source": [
        "# Reference article for using code\n",
        "\n",
        "class Sample:\n",
        "    def __init__(self, question, context, start_char_idx=None, answer_text=None, all_answers=None):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "        self.start_token_idx = -1\n",
        "        self.end_token_idx = -1\n",
        "\n",
        "    def preprocess(self):\n",
        "        # clean context and question\n",
        "        context = \" \".join(str(self.context).split())\n",
        "        question = \" \".join(str(self.question).split())\n",
        "        # tokenize context and question\n",
        "        tokenized_context = tokenizer.encode(context)\n",
        "        tokenized_question = tokenizer.encode(question)\n",
        "        # if this is validation or training sample, preprocess answer\n",
        "        if self.answer_text is not None:\n",
        "            answer = \" \".join(str(self.answer_text).split())\n",
        "            # check if end character index is in the context\n",
        "            end_char_idx = self.start_char_idx + len(answer)\n",
        "            if end_char_idx >= len(context):\n",
        "                self.skip = True\n",
        "                return\n",
        "            # mark all the character indexes in context that are also in answer     \n",
        "            is_char_in_ans = [0] * len(context)\n",
        "            for idx in range(self.start_char_idx, end_char_idx):\n",
        "                is_char_in_ans[idx] = 1\n",
        "            ans_token_idx = []\n",
        "            # find all the tokens that are in the answers\n",
        "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
        "                if sum(is_char_in_ans[start:end]) > 0:\n",
        "                    ans_token_idx.append(idx)\n",
        "            if len(ans_token_idx) == 0:\n",
        "                self.skip = True\n",
        "                return\n",
        "            # get start and end token indexes\n",
        "            self.start_token_idx = ans_token_idx[0]\n",
        "            self.end_token_idx = ans_token_idx[-1]\n",
        "        # create inputs as usual\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        # add padding if necessary\n",
        "        if padding_length > 0:\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "        self.input_word_ids = input_ids\n",
        "        self.input_type_ids = token_type_ids\n",
        "        self.input_mask = attention_mask\n",
        "        self.context_token_to_char = tokenized_context.offsets"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jY2PpigUQBM"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnCeDFB3Zz8z"
      },
      "source": [
        "def create_squad_examples(raw_data):\n",
        "    squad_examples = []\n",
        "    for item in raw_data[\"data\"]:\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                if \"answers\" in qa:\n",
        "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                    all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                    start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                    squad_eg = Sample(question, context, start_char_idx, answer_text, all_answers)\n",
        "                else:\n",
        "                    squad_eg = Sample(question, context)\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_word_ids\": [],\n",
        "        \"input_type_ids\": [],\n",
        "        \"input_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "    x = [dataset_dict[\"input_word_ids\"],\n",
        "         dataset_dict[\"input_mask\"],\n",
        "         dataset_dict[\"input_type_ids\"]]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtZCSwY7Z6NF"
      },
      "source": [
        "class ValidationCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        # convert to lower case\n",
        "        text = text.lower()\n",
        "        # remove redundant whitespaces\n",
        "        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
        "        # remove articles\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        text = re.sub(regex, \" \", text)\n",
        "        text = \" \".join(text.split())\n",
        "        return text\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # get the offsets of the first and last tokens of predicted answers\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        # for every pair of offsets\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            # take the required Sample object with the ground-truth answers in it\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            # use offsets to get back the span of text corresponding to\n",
        "            # our predicted first and last tokens\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "            normalized_pred_ans = self.normalize_text(pred_ans)\n",
        "            # clean the real answers\n",
        "            normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n",
        "            # check if the predicted answer is in an array of the ground-truth answers\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\")"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgYkU6J1c-gF"
      },
      "source": [
        "max_seq_length = 384\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "# pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n",
        "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-_geZBiZ9WG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8961265-78df-4729-e1a6-90ceb021f768"
      },
      "source": [
        "train_path = keras.utils.get_file(\"train.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\")\n",
        "eval_path = keras.utils.get_file(\"eval.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
        "with open(train_path) as f: raw_train_data = json.load(f)\n",
        "with open(eval_path) as f: raw_eval_data = json.load(f)\n",
        "max_seq_length = 384\n",
        "\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
        "input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
        "\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n",
        "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)\n",
        "train_squad_examples = create_squad_examples(raw_train_data)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n",
        "\n",
        "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(sequence_output)\n",
        "start_logits = layers.Flatten()(start_logits)\n",
        "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(sequence_output)\n",
        "end_logits = layers.Flatten()(end_logits)\n",
        "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "model = keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=[start_probs, end_probs])\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "model.compile(optimizer=optimizer, loss=[loss, loss])\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87599 training points created.\n",
            "10570 evaluation points created.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_1 (KerasLayer)      [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       768         keras_layer_1[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       768         keras_layer_1[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 384)          0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 384)          0           flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,777\n",
            "Trainable params: 109,483,776\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMczNrb7M3y-",
        "outputId": "5438915a-f13c-454e-9ad9-2b3b0afbe5d9"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzzu7xUlMx8A",
        "outputId": "8e198cdd-3ca3-4dae-e909-f6d200a8a242"
      },
      "source": [
        "model.save('drive/MyDrive/model2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 945). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 945). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/model2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/model2/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snJniStQ3Oq_",
        "outputId": "fc10227f-32f5-4cf0-ea6d-fc4a5237a8b4"
      },
      "source": [
        "# model = keras.models.load_model(\"drive/MyDrive/model\")\n",
        "# model.layers[3].trainable = False\n",
        "# model.load_weights('drive/MyDrive/weights.h5')\n",
        "# model.compile(optimizer=optimizer, loss=[loss, loss])\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 324)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 324)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, 324)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 324, 1)       768         keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 324, 1)       768         keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 324)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 324)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 324)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 324)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,777\n",
            "Trainable params: 1,536\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0sz8HqWdlRW",
        "outputId": "d87b02b4-365d-4e6b-f136-b7f5ec2c8eef"
      },
      "source": [
        "model.save('drive/MyDrive/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fce44d7d8c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('signature_function', 'signature_key'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fce44d7d8c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('signature_function', 'signature_key'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fce44d7d8c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('signature_function', 'signature_key'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 945). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 945). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QNUNoqnd9rD"
      },
      "source": [
        "model = keras.models.load_model('drive/MyDrive/model')"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPrRadImG4FE",
        "outputId": "3af449f2-27c0-44c5-c0b4-9bbfc60ff57d"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=2, batch_size=8, callbacks=[ValidationCallback(x_eval, y_eval)])\n",
        "model.save_weights('drive/MyDrive/weights.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fce40328830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fce40328830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fce40328830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8UGzYWadk7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff095eb4-9c54-4090-8735-18882fb0e92e"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=1, batch_size=8, callbacks=[ValidationCallback(x_eval, y_eval)])\n",
        "model.save_weights('drive/MyDrive/weights.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "10578/10578 [==============================] - 14264s 1s/step - loss: 7.0601 - activation_loss: 3.6187 - activation_1_loss: 3.4414\n",
            "\n",
            "epoch=1, exact match score=0.11\n",
            "Epoch 2/2\n",
            "10578/10578 [==============================] - 14550s 1s/step - loss: 6.5545 - activation_loss: 3.3685 - activation_1_loss: 3.1860\n",
            "\n",
            "epoch=2, exact match score=0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdhbqxXkqdfY"
      },
      "source": [
        "def call_pull(ticker, year, quarter,key = 'e46f1a303dafb62460de104424a00084'):\n",
        "    try:\n",
        "        transcript = requests.get(f'https://financialmodelingprep.com/api/v3/earning_call_transcript/{ticker}?quarter={quarter}&year={year}&apikey={key}').json()\n",
        "        tran = transcript[0]['content']\n",
        "        date = transcript[0]['date']\n",
        "        return tran\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_split(ticker, year, quarter):\n",
        "  text1 = call_pull(ticker, year, quarter)\n",
        "  l_total = []\n",
        "  l_parcial = []\n",
        "  if len(text1.split())//150 >0:\n",
        "    n = len(text1.split())//150\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_parcial = text1.split()[:200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "    else:\n",
        "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "  return l_total\n",
        "\n",
        "\n",
        "pull =]"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOTktaOVu5pE",
        "outputId": "03850c90-3596-4a58-8b7f-4d5e20c1cf34"
      },
      "source": [
        "context =  \"Keith Weiss: Thank you guys for taking the question and very nice quarter. Satya, I was hoping if you could help us with your view of what the enterprise spending environment looks like through this difficult period? On one side of the equation, we have very good secular trends that are still very well in place. And like you said, digital transformation is accelerating. On the other side, though, we do have difficult macro conditions out there, and we're seeing it in places like SMB and the like. Can you help us understand how that's putting out on the ground in terms of your customers? Are you still able to get those big deals over the line? And how do you see that playing out through the rest of the fiscal year? Like, how should we think about those impacts through FY21? Amy Hood: And Keith, maybe just to add to that a little bit. And I think you saw that in our bookings growth for the quarter. And increasingly, I think and people will start to focus as well on the remaining performance obligations. And you're starting to see this commitment both, in the next 12 months and then\"\n",
        "question = \"Who does Keith Weiss thank for the quarter?\"\n",
        "\n",
        "def call_pull(ticker, year, quarter,key = 'e46f1a303dafb62460de104424a00084'):\n",
        "    try:\n",
        "        transcript = requests.get(f'https://financialmodelingprep.com/api/v3/earning_call_transcript/{ticker}?quarter={quarter}&year={year}&apikey={key}').json()\n",
        "        tran = transcript[0]['content']\n",
        "        date = transcript[0]['date']\n",
        "        return tran\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_split(ticker, year, quarter):\n",
        "  text1 = call_pull(ticker, year, quarter)\n",
        "  l_total = []\n",
        "  l_parcial = []\n",
        "  if len(text1.split())//150 >0:\n",
        "    n = len(text1.split())//150\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_parcial = text1.split()[:200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "    else:\n",
        "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "  return l_total\n",
        "\n",
        "def preprocess(context, question):\n",
        "  start_token_idx = -1\n",
        "  end_token_idx = -1\n",
        "  context = \" \".join(str(context).split())\n",
        "  question = \" \".join(str(question).split())\n",
        "  # tokenize context and question\n",
        "  tokenized_context = tokenizer.encode(context)\n",
        "  tokenized_question = tokenizer.encode(question)\n",
        "\n",
        "\n",
        "  input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "  token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
        "  attention_mask = [1] * len(input_ids)\n",
        "  padding_length = max_seq_length - len(input_ids)\n",
        "  context_token_to_char = tokenized_context.offsets\n",
        "        # add padding if necessary\n",
        "  if padding_length > 0:\n",
        "    input_ids = input_ids + ([0] * padding_length)\n",
        "    attention_mask = attention_mask + ([0] * padding_length)\n",
        "    token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "  return input_ids, token_type_ids, attention_mask, start_token_idx, end_token_idx, context_token_to_char\n",
        "\n",
        "def create_inputs(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_word_ids\": [],\n",
        "        \"input_type_ids\": [],\n",
        "        \"input_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    dataset_dict['input_word_ids'] = squad_examples[0]\n",
        "    dataset_dict['input_type_ids'] = squad_examples[1]\n",
        "    dataset_dict['input_mask'] = squad_examples[2]\n",
        "    dataset_dict['start_token_idx'] = squad_examples[3]\n",
        "    dataset_dict['end_token_idx'] = squad_examples[4]\n",
        "\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array([dataset_dict[key]])\n",
        "    x = [dataset_dict[\"input_word_ids\"],\n",
        "         dataset_dict[\"input_mask\"],\n",
        "         dataset_dict[\"input_type_ids\"]]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def question_answer(ticker, year, quarter, question):\n",
        "  transcript = [\"Operator: Good day, everyone. Welcome to the Apple Incorporated Third Quarter Fiscal Year 2020 Earnings Conference Call. Today's call is being recorded. At this time, for opening remarks and introductions, I would like to turn things over to Mr. Tejas Gala, Senior Manager, Corporate Finance and Investor Relations. Please go ahead, sir. Tejas Gala: Thank you. Good afternoon and thank you for joining us. Speaking first today is Apple's CEO, Tim Cook; and he'll be followed by CFO, Luca Maestri. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements including without limitation those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook, including the potential impact of COVID-19 on the company's business and results of operations. Actual results or trends could differ materially from our forecast. For more information, please refer to the risk factors discussed in Apple's most recently filed periodic reports Form 10-K and Form 10-Q and the Form 8-K filed with the SEC today along with the associated press release. Apple assumes no obligation to update any forward-looking statements or\",\n",
        " \"from our forecast. For more information, please refer to the risk factors discussed in Apple's most recently filed periodic reports Form 10-K and Form 10-Q and the Form 8-K filed with the SEC today along with the associated press release. Apple assumes no obligation to update any forward-looking statements or information, which speak as of their respective dates. I'd now like to turn the call over to Tim for introductory remarks. Tim Cook: Thanks, Tejas. Good afternoon, everyone. Thanks for joining the call today. Before we begin, I joined the many millions across this country in mourning and memorialize Congressman John Lewis, who was laid to rest earlier today. We've lost a hero who walked among us, a leader in the truest sense who urged this country to aim higher and be better until the very end. I was humbled and fortunate to know him and as an Alabama native his example inspires me still. It now falls to every American to be a living memorial to John Lewis and to carry forward the work and the mission that defined his life. Throughout the call I'll speak in greater detail about Apple's support for equity and justice topics of great\",\n",
        " \"his example inspires me still. It now falls to every American to be a living memorial to John Lewis and to carry forward the work and the mission that defined his life. Throughout the call I'll speak in greater detail about Apple's support for equity and justice topics of great urgency on a number of fronts, but first I want to pull the lens back to consider the quarter and full. In an uncertain environment Apple saw a quarter of historic results demonstrating the important role our products play in our customers' lives. We set a June quarter record with revenue of $59.7 billion, up 11% from a year ago. Both products and services set June quarter records and grew double-digits and revenue grew in each of our geographic segments, reflecting the broad base of this success. As always and especially in times of real adversity, what makes us proud as a company is not merely what we did, but how we did it. As millions March for justice in big cities and small towns alike, we committed a $100 million to launch Apple's racial equity and justice initiative as well as new and renewed internal efforts to foster diversity\",\n",
        " \"as a company is not merely what we did, but how we did it. As millions March for justice in big cities and small towns alike, we committed a $100 million to launch Apple's racial equity and justice initiative as well as new and renewed internal efforts to foster diversity and inclusion at all levels of the company. As COVID-19 continues to represent great risks for individuals and great uncertainty for our communities, care and adaptability are defining how we conduct our work wherever we work. In some places that has met responsibly reopening our operations and retail stores with enhanced health and safety precautions. In others, where the virus has reemerge it's meant taking the challenging, but necessary step of re-closing stores. I'll touch on these topics more in a little bit. But first I want to offer some more context on the quarter's results. Due to the uncertain and ongoing impacts of COVID-19, we did not provide our typical guidance when we reported our results last quarter, but we did provide some color on how we expected the June quarter to play out. I'd like to contextualize our results in terms of that color across each of our\",\n",
        " \"and ongoing impacts of COVID-19, we did not provide our typical guidance when we reported our results last quarter, but we did provide some color on how we expected the June quarter to play out. I'd like to contextualize our results in terms of that color across each of our product categories beginning with iPhone. iPhone revenue grew 2% this quarter. In April, we expected year-over-year performance to worsen, but we saw better-than-expected demand in May and June. We attribute this increase in demand to several interactive causes including a strong iPhone SE launch, continued economic stimulus, and potentially some benefit from shelter in place restrictions lifting around the world. We expected iPad and Mac growth to accelerate and we saw very strong double-digit growth for these devices this quarter. This remarkable performance came in spite of supply constraints on both products. We're working hard to get more iPads and Macs into customers' hands as quickly as possible recognizing how integral they have become to working and learning from home providing entertainment and staying connected with loved ones. Wearables growth decelerated as we expected, but still grew by strong double-digits and set a revenue record for a non-holiday quarter. Building\",\n",
        " \"Macs into customers' hands as quickly as possible recognizing how integral they have become to working and learning from home providing entertainment and staying connected with loved ones. Wearables growth decelerated as we expected, but still grew by strong double-digits and set a revenue record for a non-holiday quarter. Building on powerful new features built into watchOS 7 and AirPods Pro announced this quarter, we are very excited about the many opportunities in front of us for this product category. These strong results helped drive our installed base of active devices to new all-time records across each of our product categories. Reflecting the deep integration of hardware, software and services, services generated a June quarter record of $13.2 billion, up 15% year-over-year. As we mentioned during our last call, there were two distinct trends we were seeing and they played out as we thought. First, results for advertising and AppleCare were impacted by the reduced level of economic activity and store closures to a degree that was in line with our expectations. Second, we had strong performance in our digital services with all-time revenue records in the App Store, Apple Music, video and cloud services as well as elevated engagement\",\n",
        " \"were impacted by the reduced level of economic activity and store closures to a degree that was in line with our expectations. Second, we had strong performance in our digital services with all-time revenue records in the App Store, Apple Music, video and cloud services as well as elevated engagement on iMessage, Siri and FaceTime. Customers are loving new offerings across Apple services like Apple News today, our new daily audio briefing and Greyhound, our new summer blockbuster starring Tom Hanks. In fact, Apple TV+ just hit a history making 95 awards nominations and 25 wins and accolades. Based on these results and our performance over the last four quarters, we are proud to announce that we have achieved our goal of doubling. Our fiscal 2016 services revenue six months ahead of schedule. We're conscious of the fact that these results stand in stark relief during a time of real economic adversity for businesses large and small and certainly for families. We do not have a zero-sum approach to prosperity and especially in times like this, we are focused on growing the pie, making sure our success isn't just our success and that everything we make, build or do is\",\n",
        " \"economic adversity for businesses large and small and certainly for families. We do not have a zero-sum approach to prosperity and especially in times like this, we are focused on growing the pie, making sure our success isn't just our success and that everything we make, build or do is geared towards creating opportunities for others. The App Store is a great example. This quarter, a new study by independent economists at the Analysis Group founded the App Store facilitated more than 0.5 trillion in commerce globally in 2019 alone. Especially in a time of COVID-19, you can measure economic resilience in the ways in which the App Store supports remote ordering for restaurants, digital commerce for small businesses and an enduring entrepreneurial opportunity for creators and visionaries. Keeping learning vibrant and impactful in the time of COVID-19 is a priority everyone shares. Earlier this month, we announced significant enhancements to the development Swift and Everyone Can Code curricula and we launched a new professional learning course available exclusively to educators. In just two weeks ago, our Community Education initiative added 10 more historically black college and university regional coding centers to our roster, bringing the total to 24 locations\",\n",
        " \"to the development Swift and Everyone Can Code curricula and we launched a new professional learning course available exclusively to educators. In just two weeks ago, our Community Education initiative added 10 more historically black college and university regional coding centers to our roster, bringing the total to 24 locations nationwide, 12 of which are HBCUs and 21 of which serve majority black and brown student populations. In Apple's backyard, we announced that we are allocating $400 million of our multi-year $2.5 billion affordable housing commitment to new housing construction, homebuyer assistance programs and support for those at greatest risk of experiencing homelessness across Silicon Valley. Apple's results this quarter are only possible due to our people and their ongoing ingenuity, flexibility, resilience and determination during these ever-changing times. I want to thank our AppleCare and retail teams who have paired exceptional service during a time of intense demand with great adaptability during a quarter where stores have reopened in some places and reclosed in others. A dedicated team of specialists and experts has shouldered the task of caring for the well-being of our teams and communities store by store, location by location with evidence driven granularity and agility that\",\n",
        " \"great adaptability during a quarter where stores have reopened in some places and reclosed in others. A dedicated team of specialists and experts has shouldered the task of caring for the well-being of our teams and communities store by store, location by location with evidence driven granularity and agility that is unrivaled anywhere. Innovation from adversity certainly define this year's Worldwide Developers Conference as well. This is an event where traditionally Apple's worldwide community of developers gathers together to share, celebrate and do big things together. Though we could not be together in person, Apple set a new standard for what online events can achieve with our celebrated all virtual event. The results here speak for themselves. More than 22 million viewers tuned in across all of Apple streams. For our developers we distributed more than 72 hours of video content. That's three full days of video. The weak saw more than 200 direct video engineering and design sessions and about 4500 person to person appointments with developers across 227 virtual labs. And of course that's even before you get to this year's announcements from iOS 14, which boasts the radical redesign to the home screen, powerful updates to messages,\",\n",
        " \"more than 200 direct video engineering and design sessions and about 4500 person to person appointments with developers across 227 virtual labs. And of course that's even before you get to this year's announcements from iOS 14, which boasts the radical redesign to the home screen, powerful updates to messages, streamlined and effortless app clips and even greater privacy transparency and controls to major updates to Apple Pencil, Siri and calling and iPad OS 14 to much anticipated sleep tracking, new fitness and wellness features and unprecedented customization and watchOS 7 to the new macOS Big Sur boasting the biggest redesign upgrade to macOS since OS X. No less important for Apple's innovation roadmap is our transition to Apple silicon for the Mac. This two-year effort will achieve both unprecedented performance for the Mac and a common architecture across all Apple products. Looking forward, we are profoundly optimistic about Apple's future and we recognize that with this success comes some real responsibility to lead with our values because those values help make that success possible in the first place. We are just as proud of our announcement this month that Apple will be fully carbon-neutral by 2030 across our entire\",\n",
        " \"future and we recognize that with this success comes some real responsibility to lead with our values because those values help make that success possible in the first place. We are just as proud of our announcement this month that Apple will be fully carbon-neutral by 2030 across our entire supply chain and including the energy use of every device we make as we are of any hardware innovation because they spring from the same instinct to leave the world better than we found it. We're committed to standing with those marching for the lives and dignity through our new $100 million commitment to Apple's racial equity and justice initiative, and we're deepening our diversity and inclusion efforts internally because our future as a business is inextricably linked with the future of our communities. There are times when things seem to move slowly when needed progress, economic or social themes bogged down when the instinct to turn away from the horizon and hold onto what you've got fields and ex-capable, and then there are times like this when people of goodwill step forward, when progressed on Moore's itself, when the insistence of hope forces something new. This is an immensely\",\n",
        " \"bogged down when the instinct to turn away from the horizon and hold onto what you've got fields and ex-capable, and then there are times like this when people of goodwill step forward, when progressed on Moore's itself, when the insistence of hope forces something new. This is an immensely challenging moment. COVID-19 is still devastating many places and we have work left to do to care for the health and well-being of the communities in which all of us live and work. But no community of people, whether a company or a country, can afford to miss this call when it comes. At Apple, we never have and we don't intend to start now. With that, I'll hand things off to Luca. Luca Maestri: Thank you, Tim. Good afternoon, everyone. Our June quarter was a testament to Apple's ability to innovate and execute during challenging times. Our results speak to the resilience of our business and the relevance of our products and services in our customers' lives. Total revenue was $59.7 billion, a new June quarter record, up 11% from a year ago, despite a 300 basis point headwind from foreign exchange. Our performance was strong across our entire\",\n",
        " \"to the resilience of our business and the relevance of our products and services in our customers' lives. Total revenue was $59.7 billion, a new June quarter record, up 11% from a year ago, despite a 300 basis point headwind from foreign exchange. Our performance was strong across our entire portfolio as we grew revenue in each of our product categories and set June quarter records for Mac, for Wearables and for services. Similarly, our results were very strong all around the world with growth in all geographic segments and new June quarter records in the Americas, in Europe, in Japan and Rest of Asia-Pacific. Products revenue was $46.5 billion, up 10% and a June quarter record. iPhone returned to growth and we saw very strong double-digit growth from iPad, Mac and Wearables. Lockdowns and point of sale closures were widespread during April and impacted our performance, but we saw demand for all products improve significantly in May and June. As a result of our strong performance and the unmatched loyalty of our customers, our installed base of active devices reached an all-time high in all of our geographic segments and all major product categories. Our services continue to grow\",\n",
        " \"demand for all products improve significantly in May and June. As a result of our strong performance and the unmatched loyalty of our customers, our installed base of active devices reached an all-time high in all of our geographic segments and all major product categories. Our services continue to grow strongly up 15% year-over-year and reached a June quarter record of $13.2 billion. We set all-time records in many services categories and June quarter records in each geographic segment. I'll cover this in more detail later. Company gross margin was 38%. This was down 40 basis points sequentially due to unfavorable FX of 90 basis points and a different mix of products partially offset by cost savings and services mix. Products gross margin was 29.7% decreasing 60 basis points sequentially due to FX and a different mix partially offset by cost savings. Services gross margin was 67.2% up 180 basis points sequentially mainly due to mix. Net income was $11.3 billion and earnings per share were $2.58, up 18% and a June quarter record. Operating cash flow was also a June quarter record at $16.3 billion, an improvement of $4.6 billion over a year ago. Let me get into more\",\n",
        " 'points sequentially mainly due to mix. Net income was $11.3 billion and earnings per share were $2.58, up 18% and a June quarter record. Operating cash flow was also a June quarter record at $16.3 billion, an improvement of $4.6 billion over a year ago. Let me get into more detail for each of our revenue categories. iPhone revenue grew 2% to $26.4 billion with customer demand improving as the quarter progressed. COVID-19 was most impactful during the first three weeks of April when lockdowns and point of sale closures became more widespread in many countries. We saw marked improvement around the world in May and June, which we attribute to an improved level of customer demand helped by the very successful launch of iPhone SE and economic stimulus packages. Our active installed base of iPhones again reached an all-time high as a result of the loyalty of our customer base and strength of our ecosystem. In fact in the US the latest survey of consumers from 451 Research indicates iPhone customer satisfaction of 98% for iPhone 11, 11 Pro and 11 Pro Max combined. Turning to services, as I said, we set a June quarter record of $13.4 billion',\n",
        " 'base and strength of our ecosystem. In fact in the US the latest survey of consumers from 451 Research indicates iPhone customer satisfaction of 98% for iPhone 11, 11 Pro and 11 Pro Max combined. Turning to services, as I said, we set a June quarter record of $13.4 billion of revenue. We had all-time record performance and strong double-digit growth in the App Store, Apple Music, video and cloud services. Our new services Apple TV+, Apple Arcade, Apple News+ and Apple Card are also contributing to overall services growth and continue to add users content and features. At the same time customer engagement in our ecosystem continues to grow at a fast pace. The number of both transacting and paid accounts on our digital content stores reached a new all-time high during the June quarter with paid accounts increasing double-digits in each of our geographic segments. In aggregate, paid subscriptions grew more than 35 million sequentially and we now have over 550 million paid subscriptions across the services on our platform, up 130 million from a year ago. With this momentum we remain confident to reach our increased target of 600 million paid subscriptions before the end of calendar',\n",
        " \"subscriptions grew more than 35 million sequentially and we now have over 550 million paid subscriptions across the services on our platform, up 130 million from a year ago. With this momentum we remain confident to reach our increased target of 600 million paid subscriptions before the end of calendar 2020. Wearables, Home and Accessories established a new June quarter record with revenue of $6.5 billion, up 17% year-over-year. Our Wearables business is now the size of a Fortune 140 company and we set June quarter records in the majority of markets we track. Importantly Apple Watch continues to extend its reach with over 75% of the customers purchasing Apple Watch during the quarter new to the product. Next, I'd like to talk about the impressive performance of Mac. Revenue was $7.1 billion, up 22% over last year and a June quarter record. We grew double digits in each geographic segment and set all-time revenue records in Japan and rest of Asia-Pacific as well as June quarter records in the Americas and Europe. Customer response to our new MacBook Air and MacBook Pro launches has been extremely strong. iPad performance was equally impressive with revenue of $6.6 billion, up 31%\",\n",
        " 'segment and set all-time revenue records in Japan and rest of Asia-Pacific as well as June quarter records in the Americas and Europe. Customer response to our new MacBook Air and MacBook Pro launches has been extremely strong. iPad performance was equally impressive with revenue of $6.6 billion, up 31% and our highest June quarter revenue in eight years. Demand was strong around the world with double-digit growth in each of our geographic segments, including a June quarter record in Greater China. The launch of our new iPad Pro has been received incredibly well in every region of the world. Both Mac and iPad are extremely relevant products in the new working and learning environments and the most recent surveys of consumers from 451 Research measured customer satisfaction at 96% for Mac and 97% for iPad. Around half of the customers purchasing Mac and iPad during the quarter were new to that product. And as a result, the active installed base for both products reached a new all-time high. Our retail business had record June quarter revenue. Thanks to the performance of our online store which had records in all geographic segments and grew across all major product categories. In',\n",
        " \"to that product. And as a result, the active installed base for both products reached a new all-time high. Our retail business had record June quarter revenue. Thanks to the performance of our online store which had records in all geographic segments and grew across all major product categories. In June, we launched Apple Card Monthly Installments for more products in our US stores allowing customers to pay for their devices all the time with 0% interest. We're very pleased with the level of customer interest this new offering has generated. In the enterprise market, we continue to see companies leverage Apple products and offerings to successfully navigate their businesses through COVID-19. In healthcare, we are seeing rapid acceleration of telehealth to support a more flexible model of patient care. Many hospitals such as UVA Health, Rush University Medical Center and UC San Diego Health are using apps on iPad and iPhone to have triage, monitor and care for patients who are at home. This helps free up hospital capacity to support patients who need inpatient care while enabling continued care for patients who do not require in-person visits. Since many call center employees are currently working remotely, Apple Business\",\n",
        " 'and iPhone to have triage, monitor and care for patients who are at home. This helps free up hospital capacity to support patients who need inpatient care while enabling continued care for patients who do not require in-person visits. Since many call center employees are currently working remotely, Apple Business Chat has proven an invaluable tool for staying connected with customers. This quarter HSBC deployed Apple Business Chat in its US and UK contact centers. Apple Business Chat provides a flexible and secured channel for digital banking assistance through a native Apple experience improving the efficiency and experience for both customers and agents. We are seeing similar adoption by hundreds of other organizations. Let me now turn to our cash position. We ended the quarter with almost $194 billion in cash plus marketable securities. We issued $8.5 billion of new term debt, retired $7.4 billion of term debt and increased short-term borrowing facilities by $1.1 billion during the quarter leaving us with total debt of $113 billion. As a result, net cash was $81 billion at the end of the quarter and we continue on our path to reaching a net cash neutral position over time. We returned over $21',\n",
        " \"short-term borrowing facilities by $1.1 billion during the quarter leaving us with total debt of $113 billion. As a result, net cash was $81 billion at the end of the quarter and we continue on our path to reaching a net cash neutral position over time. We returned over $21 billion to shareholders during the June quarter, including $3.7 billion in dividends and equivalents and $10 billion through open market repurchases of 31.3 million Apple shares. We also began a $6 billion accelerated share repurchase program in May resulting in the initial delivery and retirement of 15.2 million shares. And finally, we retired an additional 4.8 million shares in the final settlement of our 15th ASR. As we move ahead into the September quarter, I'd like to provide some color on what we are seeing, which includes the types of forward-looking information that Tejas referred to at the beginning of the call. Similar to last quarter, given the uncertainty around the world in the near-term, we will not be issuing revenue and margin guidance for the coming quarter. However, we will provide some additional insight on our expectations for the September quarter for our product categories. On iPhone, we expect\",\n",
        " 'the call. Similar to last quarter, given the uncertainty around the world in the near-term, we will not be issuing revenue and margin guidance for the coming quarter. However, we will provide some additional insight on our expectations for the September quarter for our product categories. On iPhone, we expect to see recent performance continue for our current product lineup, including the strong customer response for iPhone SE. In addition, as you know, last year we started selling new iPhones in late September. This year we project supply to be available a few weeks later. We expect the rest of our product categories to have strong year-over-year performance. For services, we expect the September quarter to have the same trends that we have observed during the June quarter except for AppleCare where during the September quarter a year ago we expanded our distribution significantly. As a consequence, we expect a difficult comp for AppleCare also considering the COVID related point of sale closures this year. For gross margin, keep in mind that we will have a different mix than in prior years as I just explained. For OpEx, we expect to be between $9.8 billion and $9.9 billion. We expect',\n",
        " \"difficult comp for AppleCare also considering the COVID related point of sale closures this year. For gross margin, keep in mind that we will have a different mix than in prior years as I just explained. For OpEx, we expect to be between $9.8 billion and $9.9 billion. We expect the tax rate to be about 16.5% and OI&E to be $50 million. Also today our Board of Directors has declared a cash dividend of $0.82 per share of common stock payable on August 13, 2020 to shareholders of record as of August 10, 2020. And finally, today we're announcing a four for one split of Apple common stock to make our stock more accessible to a broader base of investors. Each shareholder of record at the close of business on August 24, 2020 will receive three additional shares for every outstanding share held on the record date and trading will begin on a split-adjusted basis on August 31st, 2020. With that let's open the call to questions. Tejas Gala: Thank you, Luca. We ask that you limit yourself to two questions. Operator, may we please have the first question? Operator: Yes, that will be from Katy Huberty with Morgan\",\n",
        " \"will begin on a split-adjusted basis on August 31st, 2020. With that let's open the call to questions. Tejas Gala: Thank you, Luca. We ask that you limit yourself to two questions. Operator, may we please have the first question? Operator: Yes, that will be from Katy Huberty with Morgan Stanley. Katy Huberty: Thank you. Good afternoon. Tim in light of the economic adversity that you talked about in the prepared remarks, can you just walk us through how Apple is leveraging finance and trade-in programs to make technology more affordable and accessible during this period, while also addressing the opportunity to recycle and reuse products and maybe also extend that to how these programs might expand over time and then I have a follow-up. Tim Cook: Yes. As Luca mentioned, in June we actually rolled out to the overwhelming balance of our other products the ability to do interest rate, interest free financing in our stores with payments. And that's in addition to trade-in which is becoming a more common trend now which I think is terrific because it is great for the environment and it acts as a subsidy, if you will, against the price of the new\",\n",
        " \"rate, interest free financing in our stores with payments. And that's in addition to trade-in which is becoming a more common trend now which I think is terrific because it is great for the environment and it acts as a subsidy, if you will, against the price of the new phone. And so when you compound these two things with the financing and the trade-in it makes the product super affordable. And we're really happy with what we're seeing in that regard. Katy Huberty: And then, as a follow-up, just specifically to iPhone the category returned to growth. As you pointed out, the installed base is larger today. Our math would suggest that replacement cycles in some cases are elongated. And then you have the affordability element that you just discussed. Does all of that combine to build confidence that we're entering a longer period of iPhone revenue growth after what's been six quarters of decline? Tim Cook: We're very pleased with how we did on iPhone. It was better than we thought largely because as we pointed out in the prepared remarks May and June were much better. If you look at iPhone in totality the things that get\",\n",
        " \"what's been six quarters of decline? Tim Cook: We're very pleased with how we did on iPhone. It was better than we thought largely because as we pointed out in the prepared remarks May and June were much better. If you look at iPhone in totality the things that get me very optimistic is the size of the active installed base. The fact that if you look in the major geographies like the US, we had the top two selling smartphones. In the UK we had three of the top four. In Australia, we had five of the top six. And in Japan we had the top four. Urban China we were, iPhone 11 was the top selling smartphone in the country. And so these are some very different geographies with their very different competitive situations and we're doing fairly well. The iPhone SE, it's also clear that from the early data we're seeing a higher switcher number than we did in the previous year, which we feel very good about. And it also seems to appeal to some people that were holding onto the device a little longer because they wanted a smaller form factor phone. And so the\",\n",
        " \"early data we're seeing a higher switcher number than we did in the previous year, which we feel very good about. And it also seems to appeal to some people that were holding onto the device a little longer because they wanted a smaller form factor phone. And so the combination of the smaller form factor and an incredibly affordable price made the iPhone SE very popular. iPhone 11 is still the most popular smartphone, but iPhone SE definitely helped our results. And as we -- as Lucas said in his outlook, we do see that continuing into this quarter currently. Tejas Gala: Thank you, Katy. Katy Huberty: Thank you. Congrats on the quarter. Tim Cook: Thank you so much. Tejas Gala: Can we have the next question, please? Operator: Yes, that would be from Krish Sankar with Cowen & Company. Krish Sankar: Hi, thanks for taking my question. I have two of them. First one, Tim, when you look at the services business and in terms of your TV+ content production have the movement restrictions impacted the content production efforts? And along the same path four years ago your premonition on services being a $50 billion business in 2020\",\n",
        " \"have two of them. First one, Tim, when you look at the services business and in terms of your TV+ content production have the movement restrictions impacted the content production efforts? And along the same path four years ago your premonition on services being a $50 billion business in 2020 came sooner than expected, I don't know if you want to make any such forecast four years out and how you think services revenue is going to be. Then I have a follow-up for Luca. Tim Cook: I'm sorry. I missed that second question because the audio didn't come through. But I think I got the gist of the first. And that is production has been affected for Apple TV+ as I think it has for most people. We are working to get restarted. I don't have a precise date yet when we will get it restarted, but there will be some impact because we shut down in the March time frame and are yet to really restart in a significant way particularly for those that are shut in the LA area given the current status of the virus and those. And I'm sorry I missed your, the second part\",\n",
        " \"be some impact because we shut down in the March time frame and are yet to really restart in a significant way particularly for those that are shut in the LA area given the current status of the virus and those. And I'm sorry I missed your, the second part of your question. Krish Sankar: Yes, Tim, I was trying to see, four years ago you made a great prediction that services is going to be $50 billion by 2020. I wanted to see if you have any update to the prediction four years down the road? Tim Cook: We're not updating today. We feel good. We want to take the moment and feel good about achieving the doubling six months early. And we do have still hanging out there, as you know, the subscription number that we're shooting for later in the year at 600 million. So we do have that objective out there. Krish Sankar: If I could just squeeze in one for Luca. With the strong sales in Mac given the shelter-in-place, do you think the back-to-school season got pulled in by a quarter or do you expect the momentum to still continue? Thank you very much.\",\n",
        " \"have that objective out there. Krish Sankar: If I could just squeeze in one for Luca. With the strong sales in Mac given the shelter-in-place, do you think the back-to-school season got pulled in by a quarter or do you expect the momentum to still continue? Thank you very much. Luca Maestri: As I said, when I was talking about providing some commentary for the September quarter, we expect all the non-iPhone product categories to have a very strong year-over-year performance. So we definitely, I mean, the back-to-school season is clearly this one and we are very excited not only for the Mac, but also for the iPad. We've got a fantastic lineup of products and we know that these products are incredibly relevant especially given the current circumstances. So we expect the performance that we've seen for Mac in the June quarter to continue. Tejas Gala: Thank you. Can we have the next question, please? Operator: Yes. From Cross Research we'll hear from Shannon Cross. Shannon Cross: Thank you very much. Tim, can you talk a bit about what you're seeing in China? I know the revenue was up 2% and I think Luca talked about record iPad, but\",\n",
        " \"we have the next question, please? Operator: Yes. From Cross Research we'll hear from Shannon Cross. Shannon Cross: Thank you very much. Tim, can you talk a bit about what you're seeing in China? I know the revenue was up 2% and I think Luca talked about record iPad, but just curious as to given their 5G [indiscernible] how you're seeing the market play out? And then I have a follow-up. Thank you. Tim Cook: Shannon, the growth that we -- we did see growth in Greater China for the quarter of 2%, currency affected China, a bit more than in other places, it affected 400 basis points. And so in constant currency, we would have grown at 6%. As I had mentioned before, the iPhone 11 has been our best-selling phone and has been number one in urban China and so we're very, very proud of that. iPad was helped in the June quarter there by the work from home and distance learning as it was in other geographies and the Mac also grew strong double digit during the quarter. And services set a new June quarter record there. We also continue to see extremely high new customer rates\",\n",
        " \"helped in the June quarter there by the work from home and distance learning as it was in other geographies and the Mac also grew strong double digit during the quarter. And services set a new June quarter record there. We also continue to see extremely high new customer rates on Mac and iPad there, to give you a perspective, about three out of four customers that are buying the Mac are new in China and about two out of three that are buying the iPad are new. And so these are numbers that we're super proud of. Shannon Cross: Great. And then, can you talk a little bit more about the decision to bring Mac Silicon in-house, then the benefits that you expect to see or you've seen from vertical integration of acquisitions like the Intel modem business? Thanks. Tim Cook: Thanks. Yes, I mean, what we will end up -- what we'll end up with is a common architecture across all of our products, which gives us some interesting things that we can do in products that are -- that is sort of unleashes another round of innovation. And so I don't want to say a lot about\",\n",
        " \"up -- what we'll end up with is a common architecture across all of our products, which gives us some interesting things that we can do in products that are -- that is sort of unleashes another round of innovation. And so I don't want to say a lot about it, other than we are extremely excited about it, it's something that we've worked on quite a while to get to this point and we're looking forward to shipping the first Mac with Apple Silicon later in the year. Tejas Gala: Thank you, Shannon. Can we have the next question please. Operator: That will come from Amit Daryanani with Evercore. Amit Daryanani: Thanks a lot for taking my question guys. I have one and a follow-up as well. Fortunately, I guess, Tim, if I think about the strength, you're seeing with iPhones right now, do you have a sense in terms of where is this trend coming from? Is it more replacement cycles getting shorter or which is getting new customers into the iOS ecosystem because, clearly these growth rates seem fairly impressive in the context of a pandemic and upcoming refresh cycle that we have? Tim Cook: I think,\",\n",
        " \"terms of where is this trend coming from? Is it more replacement cycles getting shorter or which is getting new customers into the iOS ecosystem because, clearly these growth rates seem fairly impressive in the context of a pandemic and upcoming refresh cycle that we have? Tim Cook: I think, Amit, it's a combination of a strong launch with iPhone SE and some -- probably some pick up because of the economic stimulus that hit different countries at different points in time. And probably some of the reopening that took place across the quarter, particularly in May and June as Store started to reopen. And so it's a combination of all of those. And as you know, we've been having a strong cycle with the iPhone 11 and the 11 Pro. And so when you combine the -- a strong cycle plus and iPhone SE launch, plus the reopening of the stores, et cetera, I think there were a lot of things that we're going in the right direction there. Amit Daryanani: Perfect, that's helpful. And then I guess, Luca, if I could just follow up with you. I'd love to get your perspective on how do we think about\",\n",
        " \"the stores, et cetera, I think there were a lot of things that we're going in the right direction there. Amit Daryanani: Perfect, that's helpful. And then I guess, Luca, if I could just follow up with you. I'd love to get your perspective on how do we think about the overall 38% gross margins? What do you think of the levers to improve this as you go forward, not really September quarter, but over the next one to two years? And in that context, do you see a point where the product gross margin starts to stabilize because they have been trending somewhat lower for the last couple of quarters now. Luca Maestri: Yes. Well, let me start with what we've seen during the June quarter. We were at 38%, we were down slightly sequentially but up the same amount on a year-over-year basis. And really the big negative impact that we felt for several quarters now has been the strength of the US dollar, so the foreign exchange impact on a sequential basis was 90 basis points on a year-over-year basis was 130 basis points. So obviously that is something to keep in mind. And then, the other\",\n",
        " \"impact that we felt for several quarters now has been the strength of the US dollar, so the foreign exchange impact on a sequential basis was 90 basis points on a year-over-year basis was 130 basis points. So obviously that is something to keep in mind. And then, the other aspect; I think it's always important to keep in mind, Amit, is that we sell many different products. They have different margin profiles. And so sometimes a different mix can have an impact on the aggregate level of products gross margins and we are very pleased to see the performance of Mac, iPad and Wearables but obviously, it's a different mix. Going forward, the variables are always the same, is that the foreign exchange will continue to play an impact, the mix of products there, we're going to be selling, will have an impact as well. The commodities market has been relatively benign and we'll see how that plays out over time. As you know now for several years, we've been managing gross margin, I would say, fairly well in spite of some difficult situations like the one with the strength of the dollar and we plan to continue to\",\n",
        " \"been relatively benign and we'll see how that plays out over time. As you know now for several years, we've been managing gross margin, I would say, fairly well in spite of some difficult situations like the one with the strength of the dollar and we plan to continue to make a good trade off decisions between revenue and units and margins. Tejas Gala: Thank you, Amit. Can we have the next question, please? Operator: It will come from Kyle McNealy with Jefferies. Kyle McNealy: Hi, thanks a lot for the question. Our team in Asia recently, we did some survey work on smartphones in China. It showed that there is still a high proportion of the installed bases on 6, 7, 8 devices. I know you talked about the trade-in programs and promotions that you've been doing there. I wonder if you can tell us whether there is anything else that you're doing to get these customers in your latest technology? What made those customers be looking for and how should we think about when an upgrade cycle might come on more strongly there in China? Thanks. Tim Cook: Customers upgraded different at a different pace and I don't\",\n",
        " \"else that you're doing to get these customers in your latest technology? What made those customers be looking for and how should we think about when an upgrade cycle might come on more strongly there in China? Thanks. Tim Cook: Customers upgraded different at a different pace and I don't have in front of me the exact installed base data from China. But much like in other geographies, the upgrades have extended some, it extended some during the depths if you will of the pandemic in China and the rest of the world, and probably to some degree is happening still at this point. The key things that we can do is keep innovating, deliver product that people can't imagine, going through life about. And obviously keep rolling out these programs that makes the front-end purchase be much less, and this is things like the financing in the trade-in programs that you mentioned. And I do feel like those are going quite good in a number of geographies. Kyle McNealy: Okay, great, thanks. And one more if I may. Congrats again on the strong iPad and Mac results, that's really impressive. I guess the obvious question is, should we ever\",\n",
        " \"that you mentioned. And I do feel like those are going quite good in a number of geographies. Kyle McNealy: Okay, great, thanks. And one more if I may. Congrats again on the strong iPad and Mac results, that's really impressive. I guess the obvious question is, should we ever think about how much of that might be pull-forward and what might be the future upgrades in next few years? Anything else you can share on how you think about growth from here or whether there is a hangover period maybe after the back-to-school season or holiday season. That would be helpful. Thanks. Tim Cook: The installed base is growing and the new customer numbers that Luca went over in the aggregate are still very high in the close to 50% kind of range. And so, that to me, makes the -- bodes well for the future. There is clearly, as we had indicated, there is some amount of work from home and remote learning that do affect the results of Mac and iPad positively. They probably affect wearables and iPhone, the other direction. And -- but on Mac and iPad, these are productivity tools that people are using to\",\n",
        " \"as we had indicated, there is some amount of work from home and remote learning that do affect the results of Mac and iPad positively. They probably affect wearables and iPhone, the other direction. And -- but on Mac and iPad, these are productivity tools that people are using to stay engaged with their work or stay engaged with their school work. And we believe we're going to have a strong back to school season. Sitting here today, it certainly looks like that. Tejas Gala: Thank you, Kyle. Kyle McNealy: Great. Thanks very much. Tejas Gala: Can we have the next question, please? Operator: That will come from Cleveland Research's Ben Bollin. Ben Bollin: Good evening, everyone. Thanks for taking the question. Tim, I was hoping you could share a little bit about where you think channel inventory is? You talked about the tightness you saw exiting the June quarter for Mac and iPad. Interested, where you think inventory is across major product categories. And then I had a follow-up for Luca. Tim Cook: We usually -- we've gotten away from talking about channel inventories. But to give you a perspective sitting here looking at it, on iPhone the inventory\",\n",
        " \"for Mac and iPad. Interested, where you think inventory is across major product categories. And then I had a follow-up for Luca. Tim Cook: We usually -- we've gotten away from talking about channel inventories. But to give you a perspective sitting here looking at it, on iPhone the inventory is slightly less than it was a year ago and that's I'm saying that at a quarter end point, so at the end of Q3. And obviously iPad and Mac are constrained and so both of those are less than they were in the year ago quarter. Ben Bollin: Okay. And then, Luca, I'm interested, any color you could share about the impact COVID had on OpEx in the quarter, be it work from home, stipends, travel, other employee support costs. And also how the company is thinking about the longer-term opportunity of employees working remotely maybe more permanently many considerations and how that could influence the future OpEx? Thanks. Luca Maestri: Well, on the OpEx front, there are being obviously certain things that have been affected in terms of cost reductions. Obviously, travel, it is a perfect example. The number of meetings that we have internally, some of those\",\n",
        " \"considerations and how that could influence the future OpEx? Thanks. Luca Maestri: Well, on the OpEx front, there are being obviously certain things that have been affected in terms of cost reductions. Obviously, travel, it is a perfect example. The number of meetings that we have internally, some of those costs have been reduced. We've also invested heavily in initiatives for example, we're really trying to help during a very difficult circumstances. For example, we have had a program for example where we match our employee donations, we made donations directly as a company around the world to many institutions and governments. On a net basis, I would say probably the cost have outweighed the savings both during the March and the June quarter, but we think it's absolutely the right thing to do. From an employee perspective, what we said so far is that here in the United States, in most -- the majority of our population will continue to work from home until the end of the year. And then we'll see, I mean, we've taken an approach that we try to understand how the virus is evolving over time. We've taken a very cautious approach of both\",\n",
        " \"in most -- the majority of our population will continue to work from home until the end of the year. And then we'll see, I mean, we've taken an approach that we try to understand how the virus is evolving over time. We've taken a very cautious approach of both with our corporate facilities and with our retail stores. I think what you've seen with retail stores is that we have reopened in number of geographies around the world. We've reopened here in the United States. We've had to re-close some of the stores yet here in the United States, as the number of cases has gone up. And we will continue to track how the virus is doing. And hopefully at some point, we're going to get to a point where there is a vaccine or there is a cure. And so we will make those decisions as we get more information. Tejas Gala: Thank you. Can we have the next question, please? Operator: That will be from Jeriel Ong with Deutsche Bank. Jeriel Ong: Yes, thank you so much. I have two questions as well. I'd like to focus on the gross margin expansion within the services line\",\n",
        " \"get more information. Tejas Gala: Thank you. Can we have the next question, please? Operator: That will be from Jeriel Ong with Deutsche Bank. Jeriel Ong: Yes, thank you so much. I have two questions as well. I'd like to focus on the gross margin expansion within the services line all-time record for the quarter. I'm just curious whether you think that will sustain, I understand within services is a pretty wide range of gross margins by business, and I'm wondering if that should continue to improve. Tim Cook: Well, as you've seen, obviously, we've had a sequential expansion in gross margin for services. And that was driven primarily by mix as you said, right. We have a very broad portfolio and depending on which one of the services does better than we have an impact on Services gross margins. We like the Services business because it is -- it's a recurring type of revenue and the margins are accretive to company margin. We did over 67% this quarter, but we want to offer very competitive services across the board and the same -- I think I'm going to make the same comments that I made on products. What matters\",\n",
        " \"a recurring type of revenue and the margins are accretive to company margin. We did over 67% this quarter, but we want to offer very competitive services across the board and the same -- I think I'm going to make the same comments that I made on products. What matters to us is to be successful with everything that we do and provide great products and services to our customers. So the relative success of our products and services in the marketplace will drive to a certain extent with our margins are, that's the margins are a byproduct of our success in the marketplace. Jeriel Ong: Got it, really appreciate that. And I wanted to ask question on the Wearables segment. It seems to me that you're categorizing the Wearables business as maybe being a little bit impact from pandemic similar to the iPhones. And it's the first time that Wearables hasn't materially upsided and at least a while in recent memory. I guess the drivers of the Wearables being Watch and predominantly Watch and AirPods. What are your thoughts going forward on whether there is a little bit of pent-up demand perhaps that might resume ads that will get\",\n",
        " \"Wearables hasn't materially upsided and at least a while in recent memory. I guess the drivers of the Wearables being Watch and predominantly Watch and AirPods. What are your thoughts going forward on whether there is a little bit of pent-up demand perhaps that might resume ads that will get back to a more normalized environment? Tim Cook: I think on the Watch in particular is like the iPhone more affected by store closures, because people -- some people want to try on the Watch and see what it looks like, look at different band choices and those sorts of things. And so I think as stores closed, it puts more pressure on that. I was -- we did come out sort of the way we told you last quarter, we were going to come out from the color that we gave you. So we knew things would decelerate because of the closures. So we will end up being, we're very pleased with how we did. But the store closures definitely affect the wearables and the iPhone. Tejas Gala: Thank you, Jeriel. Jeriel Ong: Got it. Really appreciate that. Tejas Gala: Yes. Can we have the next question, please? Operator:\",\n",
        " \"of the closures. So we will end up being, we're very pleased with how we did. But the store closures definitely affect the wearables and the iPhone. Tejas Gala: Thank you, Jeriel. Jeriel Ong: Got it. Really appreciate that. Tejas Gala: Yes. Can we have the next question, please? Operator: That will come from Jim Suva with Citigroup. Jim Suva: Thank you very much. And I have two questions. I'll ask them at the same time and it's one for Tim and one for Luca. Tim, the coronavirus, your company has done a fantastic job at overcoming one of the hurdles. So congratulations to you. As you look forward, say to the Christmas holiday shopping season, and given the economic challenges around the world of virus, coronavirus and your product launches and things like that. Can you give me commentary maybe how this Christmas you're looking forward, to say, maybe some past cycles of Christmas? Because it just seems like it's a little bit different, but Apple is really showing a lot more strength coming into this Christmas than may be some of the past years. And then for Luca, I think you made a quick comment, Luca, that you\",\n",
        " \"some past cycles of Christmas? Because it just seems like it's a little bit different, but Apple is really showing a lot more strength coming into this Christmas than may be some of the past years. And then for Luca, I think you made a quick comment, Luca, that you mentioned something about a few weeks later, was Apple like iPhone, iPhone chips or product launches or maybe expand upon that. I know things are more difficult, but I didn't quite keep the commentary, it was in your prepared comments, we'll go about a few weeks late that let's just have a quick little blood. Thank you so much, gentlemen. Tim Cook: Yes, we take it one quarter at a time. And so, we'll give you color on the December quarter and October. Generally speaking, I think we need to see a vaccine or therapeutic or both. And there is some optimism around that and in that particular timeframe. And so, we'll see, I don't have any information that is publicly available there. But I think that would boost consumer confidence quite a bit if it begins to happen and I think that any kind of consumer style company would\",\n",
        " \"some optimism around that and in that particular timeframe. And so, we'll see, I don't have any information that is publicly available there. But I think that would boost consumer confidence quite a bit if it begins to happen and I think that any kind of consumer style company would benefit from that. Luca Maestri: And Jim, on the iPhone, I said in my remarks that we launched a year ago, we launched the new iPhone in late September. So I was referring to the new product. And I said that this year, the supply of the new product will be a few weeks later than that. Jim Suva: Great. Congratulations to you and your entire organization and teams. Thank you so much. Tim Cook: Thanks so much. Tejas Gala: Thank you. Can we have the next question, please? Operator: That will come from Wamsi Mohan with Bank of America. Wamsi Mohan: Hi. Yes, thank you. I was wondering if you can maybe comment on the penetration of Apple Card users in the iOS installed base? And have you seen any change in the buying behavior of Apple Card users in terms of accelerating spend on more Apple products and\",\n",
        " \"Wamsi Mohan: Hi. Yes, thank you. I was wondering if you can maybe comment on the penetration of Apple Card users in the iOS installed base? And have you seen any change in the buying behavior of Apple Card users in terms of accelerating spend on more Apple products and services? Then I have a follow-on. Tim Cook: We saw changes in consumer spending as the shutdowns occurred and the store closures occurred, we could see that across the Card. It affected the categories that you would guess the most like travel and entertainment et cetera. But overall if you sort of pull the lens out on the Apple Card, we're very happy with the number of people that have Apple Card. We believe based on what we've heard that it's the fastest rollout in the history of credit cards and so we feel very good about that. Wamsi Mohan: Okay. Thanks, Tim. And as a follow-up, now that Apple has Apple Silicon for Macs. Would you ever consider monetizing this as a merchant silicon vendor or is this going to be forever for Apple use? Tim Cook: Well, I don't want to make a forever comment, but there are\",\n",
        " \"Okay. Thanks, Tim. And as a follow-up, now that Apple has Apple Silicon for Macs. Would you ever consider monetizing this as a merchant silicon vendor or is this going to be forever for Apple use? Tim Cook: Well, I don't want to make a forever comment, but there are -- we are a product company and we love making the whole thing. And because if we can -- on the user experience in that way and with the goal of delighting the user. And that's the reason that we're doing the Apple Silicon is because we can envision some products that we can achieve with Apple Silicon that we couldn't achieve otherwise. And so that's how we look at it. Wamsi Mohan: Thanks, Tim. Tejas Gala: Thank you, Wamsi. A replay of today's call will be available for two-week on Apple podcasts as a webcast on apple.com/investor and via telephone. The numbers for the telephone replay are 888-203-1112 or 719-457-0820. Please enter confirmation code 2630782. These replays will be available by approximately 5:00 PM Pacific Time today. Members of the press with additional questions can contact Kristin Huguet at 408-974-2414. Financial analysts can contact me with additional questions at\"]\n",
        "  guesses = []\n",
        "  starts = []\n",
        "  ends = []\n",
        "  for dialogue in transcript:\n",
        "\n",
        "    x, _ = create_inputs(preprocess(dialogue, question))\n",
        "    pred_start, pred_end = model.predict(x)\n",
        "    for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "        test_sample = test_samples[idx]\n",
        "        offsets = test_sample.context_token_to_char\n",
        "        print(offsets)\n",
        "        starts.append(max(start))\n",
        "        ends.append(max(end))\n",
        "\n",
        "        start = np.argmax(start)\n",
        "        end = np.argmax(end)\n",
        "        pred_ans = None\n",
        "        if start >= len(offsets):\n",
        "            continue\n",
        "        pred_char_start = offsets[start][0]\n",
        "        if end < len(offsets):\n",
        "            pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "        else:\n",
        "            pred_ans = test_sample.context[pred_char_start:]\n",
        "            \n",
        "        # guesses.append(\"Q: \" + test_sample.question)\n",
        "        guesses.append(\"A: \" + pred_ans)\n",
        "  return starts, ends, guesses, guesses[np.argmax(start)]\n",
        "\n",
        "question_answer('AAPL', 2020, 3, question)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n",
            "[(0, 0), (0, 5), (6, 11), (11, 12), (13, 18), (19, 22), (23, 27), (28, 31), (32, 38), (39, 42), (43, 51), (52, 55), (56, 60), (61, 65), (66, 73), (73, 74), (75, 78), (78, 80), (80, 81), (82, 83), (84, 87), (88, 94), (95, 97), (98, 101), (102, 107), (108, 112), (113, 115), (116, 120), (121, 125), (126, 130), (131, 133), (134, 138), (139, 142), (143, 153), (154, 162), (163, 174), (175, 180), (181, 185), (186, 193), (194, 198), (199, 208), (209, 215), (215, 216), (217, 219), (220, 223), (224, 228), (229, 231), (232, 235), (236, 244), (244, 245), (246, 248), (249, 253), (254, 258), (259, 263), (264, 271), (272, 278), (279, 283), (284, 287), (288, 293), (294, 298), (299, 303), (304, 306), (307, 312), (312, 313), (314, 317), (318, 322), (323, 326), (327, 331), (331, 332), (333, 340), (341, 355), (356, 358), (359, 371), (371, 372), (373, 375), (376, 379), (380, 385), (386, 390), (390, 391), (392, 398), (398, 399), (400, 402), (403, 405), (406, 410), (411, 420), (421, 426), (427, 437), (438, 441), (442, 447), (447, 448), (449, 452), (453, 455), (455, 456), (456, 458), (459, 465), (466, 468), (469, 471), (472, 478), (479, 483), (484, 486), (486, 487), (488, 491), (492, 495), (496, 500), (500, 501), (502, 505), (506, 509), (510, 514), (515, 517), (518, 528), (529, 532), (533, 537), (537, 538), (538, 539), (540, 547), (548, 551), (552, 554), (555, 558), (559, 565), (566, 568), (569, 574), (575, 577), (578, 582), (583, 592), (592, 593), (594, 597), (598, 601), (602, 607), (608, 612), (613, 615), (616, 619), (620, 625), (626, 629), (630, 635), (636, 640), (641, 644), (645, 649), (649, 650), (651, 654), (655, 658), (659, 661), (662, 665), (666, 669), (670, 674), (675, 682), (683, 686), (687, 694), (695, 698), (699, 703), (704, 706), (707, 710), (711, 717), (718, 722), (722, 723), (724, 728), (728, 729), (730, 733), (734, 740), (741, 743), (744, 749), (750, 755), (756, 761), (762, 769), (770, 777), (778, 779), (779, 780), (780, 782), (782, 783), (784, 787), (788, 792), (792, 793), (794, 797), (798, 803), (803, 804), (805, 810), (811, 815), (816, 818), (819, 822), (823, 825), (826, 830), (831, 832), (833, 839), (840, 843), (843, 844), (845, 848), (849, 850), (851, 856), (857, 860), (861, 864), (865, 869), (870, 872), (873, 876), (877, 884), (884, 885), (886, 892), (893, 896), (897, 900), (901, 908), (908, 909), (910, 913), (914, 926), (926, 927), (928, 929), (930, 935), (936, 939), (940, 946), (947, 951), (952, 957), (958, 960), (961, 966), (967, 969), (970, 974), (975, 977), (978, 981), (982, 991), (992, 1003), (1004, 1015), (1015, 1016), (1017, 1020), (1021, 1024), (1024, 1025), (1025, 1027), (1028, 1036), (1037, 1039), (1040, 1043), (1044, 1048), (1049, 1059), (1060, 1064), (1064, 1065), (1066, 1068), (1069, 1072), (1073, 1077), (1078, 1080), (1081, 1087), (1088, 1091), (1092, 1096), (0, 0)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.39746365,\n",
              "  0.4893475,\n",
              "  0.2775215,\n",
              "  0.25736907,\n",
              "  0.1553607,\n",
              "  0.24192433,\n",
              "  0.38165492,\n",
              "  0.5815794,\n",
              "  0.5164758,\n",
              "  0.48802233,\n",
              "  0.25950247,\n",
              "  0.15690908,\n",
              "  0.70080304,\n",
              "  0.13720366,\n",
              "  0.27278373,\n",
              "  0.08274968,\n",
              "  0.19532734,\n",
              "  0.34159413,\n",
              "  0.5571735,\n",
              "  0.62137526,\n",
              "  0.7945955,\n",
              "  0.6085497,\n",
              "  0.2500332,\n",
              "  0.9066037,\n",
              "  0.57467556,\n",
              "  0.8393001,\n",
              "  0.81726617,\n",
              "  0.47747394,\n",
              "  0.57268107,\n",
              "  0.32954305,\n",
              "  0.79979444,\n",
              "  0.19458362,\n",
              "  0.9809544,\n",
              "  0.54752666,\n",
              "  0.5380645,\n",
              "  0.49403027,\n",
              "  0.4914952,\n",
              "  0.5062742,\n",
              "  0.5593925,\n",
              "  0.6565236,\n",
              "  0.50180686,\n",
              "  0.65183264,\n",
              "  0.7884903,\n",
              "  0.69924545,\n",
              "  0.28193575,\n",
              "  0.8624621,\n",
              "  0.35248017,\n",
              "  0.27582982,\n",
              "  0.8293982,\n",
              "  0.5339572,\n",
              "  0.44719744,\n",
              "  0.43065792],\n",
              " [0.54775375,\n",
              "  0.33348185,\n",
              "  0.440781,\n",
              "  0.2651993,\n",
              "  0.27844903,\n",
              "  0.35717687,\n",
              "  0.23621203,\n",
              "  0.6095683,\n",
              "  0.9382336,\n",
              "  0.79673773,\n",
              "  0.24359104,\n",
              "  0.28320473,\n",
              "  0.5911989,\n",
              "  0.28132096,\n",
              "  0.38223213,\n",
              "  0.23704425,\n",
              "  0.22412807,\n",
              "  0.2758784,\n",
              "  0.693249,\n",
              "  0.82026047,\n",
              "  0.6728427,\n",
              "  0.44873255,\n",
              "  0.3280887,\n",
              "  0.9079595,\n",
              "  0.49347022,\n",
              "  0.68940973,\n",
              "  0.76951575,\n",
              "  0.6461058,\n",
              "  0.39892682,\n",
              "  0.45389295,\n",
              "  0.84146404,\n",
              "  0.39413607,\n",
              "  0.97767913,\n",
              "  0.37770987,\n",
              "  0.37472758,\n",
              "  0.59164816,\n",
              "  0.78972745,\n",
              "  0.31375676,\n",
              "  0.5643264,\n",
              "  0.4760382,\n",
              "  0.37634945,\n",
              "  0.7182003,\n",
              "  0.91340935,\n",
              "  0.62773854,\n",
              "  0.30696243,\n",
              "  0.88208395,\n",
              "  0.4141005,\n",
              "  0.45578822,\n",
              "  0.66134673,\n",
              "  0.2647886,\n",
              "  0.1746655,\n",
              "  0.43094784],\n",
              " ['A: equation, we have very',\n",
              "  'A: and we',\n",
              "  'A: ',\n",
              "  \"A: through this difficult period? On one side of the equation, we have very good secular trends that are still very well in place. And like you said, digital transformation is accelerating. On the other side, though, we do have difficult macro conditions out there, and we're seeing it in places like SMB and the like. Can you help us understand how that's putting out on the ground in terms of your customers? Are you still able to get those big deals over the line? And how do you see that playing out through the rest of the fiscal year? Like, how should we think about those impacts through FY21? Amy Hood: And Keith, maybe just to add to that a little bit. And I think you saw that in our booking\",\n",
              "  'A: you guys for taking the question and very nice quarter. Satya, I was hoping if you could help us with your view of what the enterprise spending environment looks like through this difficult period? On one side of the equation, we have very good secular trends that are still very well in place. And like',\n",
              "  'A: transformation is accelerating. On the other',\n",
              "  'A: the like.',\n",
              "  'A: have difficult macro conditions out there',\n",
              "  'A: Hood: And Keith, maybe',\n",
              "  'A: hoping if you could help us with',\n",
              "  'A: ',\n",
              "  \"A: ? On one side of the equation, we have very good secular trends that are still very well in place. And like you said, digital transformation is accelerating. On the other side, though, we do have difficult macro conditions out there, and we're seeing it in places like SMB and the like. Can you help us understand how\",\n",
              "  'A: ? Like, how',\n",
              "  \"A: are still very well in place. And like you said, digital transformation is accelerating. On the other side, though, we do have difficult macro conditions out there, and we're seeing it in places like SMB and the like. Can you help us understand how that's putting out on the ground in terms of your customers? Are you still able to get those big deals over the line? And how do you see that playing out through the rest of the fiscal year? Like, how should we think about those impacts through FY21? Amy Hood: And Keith, maybe just to add to that a little bit. And I think you saw that in our bookings growth for the quarter. And increasingly, I think and people will start to focus as well on the remaining performance obligations\",\n",
              "  'A: On the other side,',\n",
              "  'A: you saw that in our bookings growth',\n",
              "  'A: equation, we have very good secular trends that are still very well in',\n",
              "  'A: in terms',\n",
              "  'A: well on the',\n",
              "  'A: this difficult period',\n",
              "  'A: other side',\n",
              "  'A: ',\n",
              "  \"A: 're\",\n",
              "  'A: the remaining performance',\n",
              "  'A: us with your',\n",
              "  'A: our booking',\n",
              "  'A: question and',\n",
              "  'A: customers? Are',\n",
              "  'A: and the',\n",
              "  \"A: . And I think you saw that in our bookings growth for the quarter. And increasingly, I think and people will start to focus as well on the remaining performance obligations. And you're starting to see this commitment both, in the next 12 months and then\",\n",
              "  'A: saw that in',\n",
              "  'A: will start to focus as well',\n",
              "  'A: impacts through',\n",
              "  \"A: how that'\",\n",
              "  'A: good secular',\n",
              "  'A: you see that playing',\n",
              "  'A: . Sat',\n",
              "  'A: ',\n",
              "  'A: I think and people',\n",
              "  'A: deals over',\n",
              "  'A: like SMB',\n",
              "  'A: and people will start',\n",
              "  'A: quarter. Satya',\n",
              "  'A: think you saw',\n",
              "  'A: you guys for taking the question and very nice quarter. Satya, I was hoping if you could help us with your view of what the enterprise spending',\n",
              "  'A: your customers? Are you',\n",
              "  \"A: . And you're starting to see this commitment\",\n",
              "  'A: through this difficult period? On one side of the',\n",
              "  'A: over the',\n",
              "  'A: of the',\n",
              "  'A: Keith Weiss: Thank',\n",
              "  'A: through FY'],\n",
              " 'A: equation, we have very')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgcrP3wGHQnq",
        "outputId": "ee5a4a30-3b6d-4599-c2ca-fb995a35de72"
      },
      "source": [
        "x = [0.39746365,\n",
        "  0.4893475,\n",
        "  0.2775215,\n",
        "  0.25736907,\n",
        "  0.1553607,\n",
        "  0.24192433,\n",
        "  0.38165492,\n",
        "  0.5815794,\n",
        "  0.5164758,\n",
        "  0.48802233,\n",
        "  0.25950247,\n",
        "  0.15690908,\n",
        "  0.70080304,\n",
        "  0.13720366,\n",
        "  0.27278373,\n",
        "  0.08274968,\n",
        "  0.19532734,\n",
        "  0.34159413,\n",
        "  0.5571735,\n",
        "  0.62137526,\n",
        "  0.7945955,\n",
        "  0.6085497,\n",
        "  0.2500332,\n",
        "  0.9066037,\n",
        "  0.57467556,\n",
        "  0.8393001,\n",
        "  0.81726617,\n",
        "  0.47747394,\n",
        "  0.57268107,\n",
        "  0.32954305,\n",
        "  0.79979444,\n",
        "  0.19458362,\n",
        "  0.9809544,\n",
        "  0.54752666,\n",
        "  0.5380645,\n",
        "  0.49403027,\n",
        "  0.4914952,\n",
        "  0.5062742,\n",
        "  0.5593925,\n",
        "  0.6565236,\n",
        "  0.50180686,\n",
        "  0.65183264,\n",
        "  0.7884903,\n",
        "  0.69924545,\n",
        "  0.28193575,\n",
        "  0.8624621,\n",
        "  0.35248017,\n",
        "  0.27582982,\n",
        "  0.8293982,\n",
        "  0.5339572,\n",
        "  0.44719744,\n",
        "  0.43065792]\n",
        "\n",
        "  \n",
        "x[np.argmax(x)]\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9809544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZrNIPqnbkUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480bdb44-4fd8-4f9f-8d88-e05cc012211a"
      },
      "source": [
        "data = {\"data\":\n",
        "    [\n",
        "        {\"title\": \"Project Apollo\",\n",
        "         \"paragraphs\": [\n",
        "             {\n",
        "                 \"context\": \"Keith Weiss: Thank you guys for taking the question and very nice quarter. Satya, I was hoping if you could help us with your view of what the enterprise spending environment looks like through this difficult period? On one side of the equation, we have very good secular trends that are still very well in place. And like you said, digital transformation is accelerating. On the other side, though, we do have difficult macro conditions out there, and we're seeing it in places like SMB and the like. Can you help us understand how that's putting out on the ground in terms of your customers? Are you still able to get those big deals over the line? And how do you see that playing out through the rest of the fiscal year? Like, how should we think about those impacts through FY21? Amy Hood: And Keith, maybe just to add to that a little bit. And I think you saw that in our bookings growth for the quarter. And increasingly, I think and people will start to focus as well on the remaining performance obligations. And you're starting to see this commitment both, in the next 12 months and then\",\n",
        "\n",
        "                 \"qas\": [\n",
        "                     {\"question\": \"Who does Keith Weiss thank for the quarter?\",\n",
        "                      \"id\": \"Q1\"}\n",
        "                 ]}]}]}\n",
        "\n",
        "test_samples = create_squad_examples(data)\n",
        "x_test, _ = create_inputs_targets(test_samples)\n",
        "pred_start, pred_end = model.predict(x_test)\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "    test_sample = test_samples[idx]\n",
        "    offsets = test_sample.context_token_to_char\n",
        "    start = np.argmax(start)\n",
        "    end = np.argmax(end)\n",
        "    pred_ans = None\n",
        "    if start >= len(offsets):\n",
        "        continue\n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "        pred_ans = test_sample.context[pred_char_start:]\n",
        "    print(\"Q: \" + test_sample.question)\n",
        "    print(\"A: \" + pred_ans)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q: Who does Keith Weiss thank for the quarter?\n",
            "A: guys\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AyF_K9IOJbI",
        "outputId": "a58b76dd-1629-49f5-c957-08a943234ba6"
      },
      "source": [
        "np.array(x).shape"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 384)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKMIUK_AQU_J",
        "outputId": "bd16b82a-355d-4aec-8dbb-2bc7e0264465"
      },
      "source": [
        "x_test[0].shape"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 384)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPRrZs1oQZdc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kkaqM_xMbQ8",
        "outputId": "84239b3b-6a68-4a63-dd14-222f9a0f2d66"
      },
      "source": [
        "len(x_test[0])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_HQ91jCW7ZJ",
        "outputId": "0236563e-eeae-4159-a62c-1c7658cc5cfd"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "project_id = 'fine-booking-311217'\n",
        "!gcloud config set project {project_id}\n",
        "!gsutil ls\n",
        "\n",
        "bucket_name = 'bertearnings'\n",
        "!gsutil cp ./model gs://{bucket_name}/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "gs://bertearnings/\n",
            "gs://squad_bucket_earningcalls/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfWAUddtnxsg",
        "outputId": "62424ea9-c95c-4ef4-b452-382a55c83d0b"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6lmSTk4r_fw",
        "outputId": "f975acc6-857c-4a53-b74e-07e487cb1856"
      },
      "source": [
        "x_test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 101, 1996, 9348, ...,    0,    0,    0],\n",
              "        [ 101, 1996, 9348, ...,    0,    0,    0],\n",
              "        [ 101, 1996, 9348, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 1996, 9348, ...,    0,    0,    0],\n",
              "        [ 101, 1996, 9348, ...,    0,    0,    0],\n",
              "        [ 101, 1996, 9348, ...,    0,    0,    0]]),\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdMFsOa6xtWN",
        "outputId": "e9dc4610-3277-4408-fc01-f98b132319ed"
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[2.9376775e-05, 1.2896392e-03, 9.7088115e-03, ..., 3.2969922e-06,\n",
              "         1.3692716e-06, 3.4124764e-06],\n",
              "        [2.4817855e-05, 1.2788997e-03, 9.5804995e-03, ..., 3.2514101e-06,\n",
              "         2.3403268e-06, 4.4213357e-06],\n",
              "        [2.7848966e-05, 1.5400385e-03, 5.3807553e-03, ..., 4.2285919e-06,\n",
              "         3.5824094e-06, 2.8510215e-06],\n",
              "        ...,\n",
              "        [4.4388922e-05, 1.3668780e-03, 5.1389472e-03, ..., 4.2793922e-06,\n",
              "         2.5231227e-06, 9.4199521e-07],\n",
              "        [2.4383467e-05, 1.2265563e-03, 5.7311212e-03, ..., 3.6154104e-06,\n",
              "         2.6222599e-06, 7.0049941e-06],\n",
              "        [1.3428788e-05, 1.6377075e-03, 8.8680536e-03, ..., 3.6995511e-06,\n",
              "         3.4578418e-06, 3.1833752e-06]], dtype=float32),\n",
              " array([[4.3742621e-06, 1.5129067e-05, 1.7171468e-03, ..., 2.5177048e-06,\n",
              "         1.9730876e-05, 9.8103874e-06],\n",
              "        [9.0737913e-06, 1.9965833e-05, 2.1719036e-03, ..., 9.0842250e-06,\n",
              "         6.2047770e-06, 3.4019190e-06],\n",
              "        [1.8196361e-05, 2.4472245e-05, 1.4396325e-03, ..., 6.2172517e-06,\n",
              "         8.4603580e-06, 6.5093450e-06],\n",
              "        ...,\n",
              "        [1.9587906e-05, 2.0423284e-05, 1.3894396e-03, ..., 1.3237166e-05,\n",
              "         1.0818305e-05, 1.4128566e-05],\n",
              "        [5.1728275e-06, 2.0585047e-05, 1.2214262e-03, ..., 1.3274200e-05,\n",
              "         8.6551509e-06, 4.7830295e-06],\n",
              "        [4.5077563e-06, 1.7673945e-05, 1.7483955e-03, ..., 6.5942017e-06,\n",
              "         7.7640607e-06, 4.9147625e-06]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}
>>>>>>> 3ee3ee257b841114600d41930e4e3ff77c971e13
